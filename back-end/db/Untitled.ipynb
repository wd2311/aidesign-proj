{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys._enablelegacywindowsfsencoding()\n",
    "\n",
    "from os.path import join\n",
    "import csv\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "base_dir = u\"C:/D-drive-18921/College/AI System Design/aidesign-proj/back-end/data\"\n",
    "\n",
    "recipes_filename = 'recipeslist.csv'\n",
    "duration_filename = 'shelf_life.csv'\n",
    "\n",
    "recipe_path= join(base_dir, recipes_filename)\n",
    "duration_path= join(base_dir, duration_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d1b0fd7855da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# #             continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         print(row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#def load_duration(duration_path):\n",
    "# with open(duration_path, 'r', encoding='utf-8') as f:\n",
    "#     reader = csv.reader(f, delimiter=',')\n",
    "#     for i, row in enumerate(reader):\n",
    "# #         if not row:\n",
    "# #             continue\n",
    "# #         if i==0:\n",
    "# #             continue\n",
    "#         print(row)\n",
    "df = pd.read_csv(duration_path, encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsed_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'comment': 'low-sodium vegetable or chicken'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'input': '1 1/2 cups whipping cream', 'displ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'comment': 'sometimes called anise stalks di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'comment': 'extra-virgin', 'name': 'olive oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'comment': '1 12-ounce package frozen, thawe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  parsed_ingredients\n",
       "0  [{'comment': 'low-sodium vegetable or chicken'...\n",
       "1  [{'input': '1 1/2 cups whipping cream', 'displ...\n",
       "2  [{'comment': 'sometimes called anise stalks di...\n",
       "3  [{'comment': 'extra-virgin', 'name': 'olive oi...\n",
       "4  [{'comment': '1 12-ounce package frozen, thawe..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# class Recipe(Base):\n",
    "#     __tablename__ = 'recipe'\n",
    "#     recipe_id = Column(Integer, primary_key=True)\n",
    "#     recipe_name = Column(String(100))\n",
    "#     ingredients = Column(String(2000), nullable=False)\n",
    "#     method = Column(String(250), nullable=False)\n",
    "#     recipe_img = Column(String(200), nullable=True)\n",
    "\n",
    "#     recipe_yield = Column(Integer, nullable=True)\n",
    "#     calories = Column(String(10), nullable=False)\n",
    "#     carbohydrates = Column(String(10), nullable=False)\n",
    "#     protein = Column(String(10), nullable=False)\n",
    "#     fiber = Column(String(10), nullable=False)\n",
    "#     fat = Column(String(10), nullable=False)\n",
    "#     salt = Column(String(10), nullable=False)\n",
    "#     sugars = Column(String(10), nullable=False)\n",
    "#     saturated_fat = Column(String(10), nullable=False)\n",
    "\n",
    "#recipe_path = 'recipeslist.csv'\n",
    "import json\n",
    "recipe_path = 'C:/D-drive-18921/College/AI System Design/combined_recipes_with_parsed_ingredients.json'\n",
    "# def load_recipes(recipes_filename):\n",
    "with open(recipe_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "#     reader = csv.reader(f, delimiter=',')\n",
    "#     for i, row in enumerate(reader):\n",
    "#         if not row:\n",
    "#             continue\n",
    "#         if i==0:\n",
    "#             continue\n",
    "#         recipe_id = i\n",
    "#         name = row[0]\n",
    "#         nutrition = row[3]\n",
    "# #         calories = int(nutrition['kcal'])\n",
    "# #         recipe_fat = nutrition['fat']\n",
    "# #         recipe_saturated_fat = nutrition['saturates']\n",
    "# #         recipe_carbohyrdrates = nutrition['carbs']\n",
    "# #         recipe_sugars = nutrition['sugars']\n",
    "# #         recipe_fiber = nutrition['fibre']\n",
    "# #         recipe_protein = nutrition['protein']\n",
    "# #         recipe_salt = nutrition['salt']\n",
    "#         ingredients_list = row[4]\n",
    "#         method = row[5]\n",
    "#         time = row[6]\n",
    "#         servings = row[8]\n",
    "#         img_url = row[9]\n",
    "        \n",
    "#         print(recipe_id, type(recipe_id))\n",
    "#         print(name, type(name))\n",
    "#         print(nutrition, type(nutrition))\n",
    "#         print(method, type(method))\n",
    "#         print(time, type(time))\n",
    "#         print(servings, type(servings))\n",
    "#         print(img_url, type(img_url))\n",
    "#         break\n",
    "\n",
    "# #             recipe = Recipe(recipe_id=recipe_id,\n",
    "# #                 recipe_name=name,\n",
    "# #                 recipe_image=img_url,\n",
    "# #                 method = method,\n",
    "# #                 ingredients=ingredients_list,\n",
    "# #                 recipe_yield=servings,\n",
    "# #                 calories=calories,\n",
    "# #                 carbohydrates=recipe_carbohydrates,\n",
    "# #                 protein=recipe_protein,\n",
    "# #                 fiber=recipe_fiber,\n",
    "# #                 fat=recipe_fat,\n",
    "# #                 salt = recipe_salt,\n",
    "# #                 sugars=recipe_sugars,\n",
    "# #                 saturated_fat=recipe_saturated_fat,\n",
    "# #                 )\n",
    "# #             session.add(recipe)\n",
    "# #         session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shreya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bunch', 'g', 'branch', 'can', 'pound fillet', '2-inch-thick', 'chilled', 'chunk', 'piece stick', 'stick', 'half', 'dozen', 'cup stalk', 'packet', 'bunch tablespoon', 'clove teaspoon', 'tsp.', 'sprig tablespoon', 'plump clove', 'tablespoon head', 'ounce', 'cup ounce', 'strip', 'slice', 'head teaspoon', 'twist', 'sprig teaspoon', 'bag', 'tablespoon clove', 'envelope', 'teaspoon tablespoon', 'sheet', 'cupsMexican-style', 'pound bulb', 'sprig cup', 'dash', 'lb', 'slice teaspoon', 'liter', 'ear cup', 'piece', 'pinch teaspoon', 'pound slice', 'liters', 'ounce tablespoon', 'drop', 'cup teaspoon', 'pound cup', 'gallon', 'head', '1 3/4-pound', 'pound ounce', 'ounce teaspoon', 'ear', 'fillet', 'cup sprig', 'leaf', 'bowl', 'half slice', 'teaspoon', 'stalk tablespoon', 'pint ounce', 'tsp', 'bottle', 'cup tablespoon', 'fillet teaspoon', 'cup piece', 'head clove', 'tablespoon ounce', 'tablespoon', 'ounce slice', 'cup clove', 'stalk teaspoon', 'rack', 'bunch pound', 'piece fillet', 'cloves;', 'tablespoon teaspoon', 'tablespoon cup', 'teaspoon pinch', 'ounce sprig', 'bulb', 'pound piece', 'oz', 'wedge', 'scoop', 'ounce cup', 'bunch head', 'box', 'cupturkey', 'bulb tablespoon', 'knob', 'pound', 'bunch ounce', 'litres', 'cupsturkey', 'pinch', 'stalk cup', 'tablespoon sprig', 'stalk', 'quart cup', 'stick tablespoon', 'tbsp', 'sprig', 'quart sprig', 'cup', 'piece teaspoon', 'half-pint', 'pound head', 'can ounce', 'block', 'tablespoon pound', 'slab', 'splashes', 'teaspoon cup', 'quart', 'pint cup', 'bunch clove', 'handful', 'gram', 'c.', 'clove', 'loaf', 'clove tablespoon', 'slice pound', 'cup pound', 'qt', 'lb.', 'pint', 'lbs', 'seeded', 'ml', '26-ounce', 'cup strip', 'cup slice', 'package', 'teaspoon piece', 'cube', 'pound tablespoon', 'fifth'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "units = set()\n",
    "for x in data['parsed_ingredients']:\n",
    "    for r in x:\n",
    "        if 'unit' in list(r.keys()):\n",
    "            u = r['unit']\n",
    "            q = r['quantity']\n",
    "            words = u.split()\n",
    "            units.add(\" \".join(sorted(set(words), key=words.index)))\n",
    "units= list(units)\n",
    "\n",
    "def convert_weight(given_unit, given_quantity):\n",
    "    #### convert all weights to pounds\n",
    "    if given_unit=='g':\n",
    "        return 0.00220462*given_quantity\n",
    "    if given_unit=='oz':\n",
    "        return 0.0625*given_quantity\n",
    "    if given_unit=='cup':\n",
    "        return 0.52*given_quantity\n",
    "    if given_unit=='tbsp':\n",
    "        return 0.0326*given_quantity\n",
    "    if given_unit=='tsp':\n",
    "        return 0.010866*given_quantity\n",
    "\n",
    "def convert_weight(given_unit, given_quantity):\n",
    "    #### convert all weights to pint\n",
    "    if given_unit=='oz' or given_unit=='fl oz':\n",
    "        return 0.0625*given_quantity\n",
    "    if given_unit=='l':\n",
    "        return 2.11338*given_quantity\n",
    "    if given_unit=='ml':\n",
    "        return 0.002113*given_quantity\n",
    "    if given_unit=='gal':\n",
    "        return 8*given_quantity\n",
    "    if given_unit=='qt':\n",
    "        return 2*given_quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set(\n",
    ")\n",
    "for x in data['parsed_ingredients']:\n",
    "    for r in x:\n",
    "        if 'unit' in list(r.keys()):\n",
    "            u = r['unit']\n",
    "            q = r['quantity']\n",
    "            words = u.split()\n",
    "            units.add(\" \".join(sorted(set(words), key=words.index)))\n",
    "print(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = list(set(req['unit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(num, unit, ingred):\n",
    "    the_unit = \"\"\n",
    "    weight = 0\n",
    "    volume = False\n",
    "    mass = False\n",
    "    quantity = False\n",
    "    \n",
    "    # Testing for volume\n",
    "    if \"gal\" in unit or 'gallon' in unit:\n",
    "        the_unit = \"gallon\"\n",
    "        weight = 3785.41\n",
    "        volume = True\n",
    "    elif \"quart\" in unit or \"qt\" in unit or \"q\" in unit:\n",
    "        the_unit = \"quart\"\n",
    "        weight = 946.353\n",
    "        volume = True\n",
    "    elif \"pt\" in unit or \"pint\" in unit:\n",
    "        the_unit = \"pint\"\n",
    "        weight = 473.176\n",
    "        volume = True\n",
    "    elif \"cup\" in unit or 'c' == unit:\n",
    "        the_unit = \"cup\"\n",
    "        weight = 240\n",
    "        volume = True\n",
    "    elif (\"fl\" in unit and \"oz\" in unit) or (\"fl\" in unit and \"ounce\" in unit):\n",
    "        the_unit = \"fl oz\"\n",
    "        weight = 29.5735\n",
    "        volume = True\n",
    "    elif \"tbsp\" in unit or \"table\" in unit or \"tablespoon\" in unit:\n",
    "        the_unit = \"tablespoon\"\n",
    "        weight = 14.7868\n",
    "        volume = True\n",
    "    elif \"tsp\" in unit or \"tea\" in unit:\n",
    "        the_unit = \"teaspoon\"\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "    elif \"ml\" in unit or \"milli\" in unit:\n",
    "        the_unit = \"milliliter\"\n",
    "        weight = 1\n",
    "        volume = True\n",
    "    elif \"liter\" in unit or \"l\" == unit:\n",
    "        the_unit = \"liter\"\n",
    "        weight = 1000\n",
    "        volume = True\n",
    "    elif \"pinch\" in unit or \"bit\" or \"dash\" in unit: # extraneous cases\n",
    "        # Vocab words that we'll estimate to half a teaspoon\n",
    "        the_unit = \"teaspoon\"\n",
    "        num = 0.5\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "    elif \"drop\" in unit:\n",
    "        the_unit = \"teaspoon\"\n",
    "        num = 0.2\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "      \n",
    "    # Testing for mass\n",
    "    elif \"metric ton\" in unit or \"mt\" in unit or \"m t\" in unit:\n",
    "        the_unit = \"metric ton\"\n",
    "        weight = 1e6\n",
    "        mass = True\n",
    "    elif \"kilo\" in unit or \"kg\" in unit:\n",
    "        the_unit = \"kilogram\"\n",
    "        weight = 1000\n",
    "        mass = True\n",
    "    elif \"gram\" in unit or \"g\" == unit:\n",
    "        the_unit = \"gram\"\n",
    "        weight = 1\n",
    "        mass = True\n",
    "    elif \"milli\" in unit or \"mg\" in unit:\n",
    "        the_unit = \"milligram\"\n",
    "        weight = 0.001\n",
    "        mass = True\n",
    "    elif (\"micro\" in unit and \"wave\" not in unit) or \"Î¼g\" in unit or \"mcg\" in unit:\n",
    "        the_unit = \"microgram\"\n",
    "        weight = 1e-6\n",
    "        mass = True\n",
    "    elif \"ton\" in unit or \"t\" == unit:\n",
    "        the_unit = \"ton\"\n",
    "        weight = 907185\n",
    "        mass = True\n",
    "    elif \"stone\" in unit or \"st\" == unit:\n",
    "        the_unit = \"stone\"\n",
    "        weight = 6350.29\n",
    "        mass = True\n",
    "    elif \"pound\" in unit or \"lb\" in unit:\n",
    "        the_unit = \"pound\"\n",
    "        weight = 453.592\n",
    "        mass = True\n",
    "    elif \"ounce\" in unit or \"ozs\" in unit or \"oz\" in unit:\n",
    "        the_unit = \"ounces\"\n",
    "        weight = 28.3495\n",
    "        mass = True\n",
    "    else: # if no match, we express the ingredient as a quantity instead of a unit of measure\n",
    "        quantity = True\n",
    "        weight = 1\n",
    "        \n",
    "    # Convert the unit\n",
    "    output = round(weight * num, 3)\n",
    "    if volume:\n",
    "        # print('Converted', the_unit, 'to milliliters')\n",
    "        mass = 0\n",
    "        volume = output\n",
    "        cols = [ingred + '_mass', ingred + '_volume']\n",
    "        measurements = [mass, volume]\n",
    "    elif mass:\n",
    "        # print('Converted', the_unit, 'to grams')\n",
    "        mass = output\n",
    "        volume = 0\n",
    "        cols = [ingred + '_mass', ingred + '_volume']\n",
    "        measurements = [mass, volume]\n",
    "    elif quantity:\n",
    "        cols = [unit]\n",
    "        measurements = [output]\n",
    "        # print('Ingredient expressed as quantity')\n",
    "    # print(output)\n",
    "    return measurements, cols, quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
