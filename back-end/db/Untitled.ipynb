{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys._enablelegacywindowsfsencoding()\n",
    "\n",
    "from os.path import join\n",
    "import csv\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "base_dir = u\"C:/D-drive-18921/College/AI System Design/aidesign-proj/back-end/data\"\n",
    "\n",
    "recipes_filename = 'recipeslist.csv'\n",
    "duration_filename = 'shelf_life.csv'\n",
    "\n",
    "recipe_path= join(base_dir, recipes_filename)\n",
    "duration_path= join(base_dir, duration_filename)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db.csv', encoding='latin-1')\n",
    "df = df[df['ingredients']!= '[]']\n",
    "df.to_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:/D-drive-18921/College/AI System Design/ingredient-phrase-tagger/final_parsing/parsed_ingredients.csv', encoding='latin-1')\n",
    "df.columns = ['recipe_id', 'parsed_ingredients']\n",
    "df.shape\n",
    "df1 = pd.read_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db.csv', encoding='latin-1')\n",
    "df1['parsed_ingredients'] = df['parsed_ingredients']\n",
    "df1.head()\n",
    "df1.to_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db_parsed.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11387, 12)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
=======
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d1b0fd7855da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# #             continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         print(row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#def load_duration(duration_path):\n",
    "# with open(duration_path, 'r', encoding='utf-8') as f:\n",
    "#     reader = csv.reader(f, delimiter=',')\n",
    "#     for i, row in enumerate(reader):\n",
    "# #         if not row:\n",
    "# #             continue\n",
    "# #         if i==0:\n",
    "# #             continue\n",
    "#         print(row)\n",
    "df = pd.read_csv(duration_path, encoding='utf-8')\n",
    "df"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
=======
   "execution_count": 38,
>>>>>>> master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <th>1</th>\n",
=======
       "      <th>parsed_ingredients</th>\n",
>>>>>>> master
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>[{u'input': u'250 gram macaroni', u'qty': u'25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{u'comment': u'plus a drizzle to serve (optio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{u'comment': u'cut into individual ribs', u'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{u'comment': u', finely chopped', u'name': u'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{u'input': u'50 millilitre cherry brandy liqu...</td>\n",
=======
       "      <td>[{'comment': 'low-sodium vegetable or chicken'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'input': '1 1/2 cups whipping cream', 'displ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'comment': 'sometimes called anise stalks di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'comment': 'extra-virgin', 'name': 'olive oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'comment': '1 12-ounce package frozen, thawe...</td>\n",
>>>>>>> master
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   0                                                  1\n",
       "0  0  [{u'input': u'250 gram macaroni', u'qty': u'25...\n",
       "1  1  [{u'comment': u'plus a drizzle to serve (optio...\n",
       "2  2  [{u'comment': u'cut into individual ribs', u'i...\n",
       "3  3  [{u'comment': u', finely chopped', u'name': u'...\n",
       "4  4  [{u'input': u'50 millilitre cherry brandy liqu..."
      ]
     },
     "execution_count": 17,
=======
       "                                  parsed_ingredients\n",
       "0  [{'comment': 'low-sodium vegetable or chicken'...\n",
       "1  [{'input': '1 1/2 cups whipping cream', 'displ...\n",
       "2  [{'comment': 'sometimes called anise stalks di...\n",
       "3  [{'comment': 'extra-virgin', 'name': 'olive oi...\n",
       "4  [{'comment': '1 12-ounce package frozen, thawe..."
      ]
     },
     "execution_count": 38,
>>>>>>> master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('C:/D-drive-18921/College/AI System Design/ingredient-phrase-tagger/final_parsing/parsed_ingredients_1.csv', encoding='latin-1', header=None)\n",
    "df2 = pd.read_csv('C:/D-drive-18921/College/AI System Design/ingredient-phrase-tagger/final_parsing/parsed_ingredients_2.csv', encoding='latin-1', header=None)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "df.head()"
=======
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# class Recipe(Base):\n",
    "#     __tablename__ = 'recipe'\n",
    "#     recipe_id = Column(Integer, primary_key=True)\n",
    "#     recipe_name = Column(String(100))\n",
    "#     ingredients = Column(String(2000), nullable=False)\n",
    "#     method = Column(String(250), nullable=False)\n",
    "#     recipe_img = Column(String(200), nullable=True)\n",
    "\n",
    "#     recipe_yield = Column(Integer, nullable=True)\n",
    "#     calories = Column(String(10), nullable=False)\n",
    "#     carbohydrates = Column(String(10), nullable=False)\n",
    "#     protein = Column(String(10), nullable=False)\n",
    "#     fiber = Column(String(10), nullable=False)\n",
    "#     fat = Column(String(10), nullable=False)\n",
    "#     salt = Column(String(10), nullable=False)\n",
    "#     sugars = Column(String(10), nullable=False)\n",
    "#     saturated_fat = Column(String(10), nullable=False)\n",
    "\n",
    "#recipe_path = 'recipeslist.csv'\n",
    "import json\n",
    "recipe_path = 'C:/D-drive-18921/College/AI System Design/combined_recipes_with_parsed_ingredients.json'\n",
    "# def load_recipes(recipes_filename):\n",
    "with open(recipe_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "#     reader = csv.reader(f, delimiter=',')\n",
    "#     for i, row in enumerate(reader):\n",
    "#         if not row:\n",
    "#             continue\n",
    "#         if i==0:\n",
    "#             continue\n",
    "#         recipe_id = i\n",
    "#         name = row[0]\n",
    "#         nutrition = row[3]\n",
    "# #         calories = int(nutrition['kcal'])\n",
    "# #         recipe_fat = nutrition['fat']\n",
    "# #         recipe_saturated_fat = nutrition['saturates']\n",
    "# #         recipe_carbohyrdrates = nutrition['carbs']\n",
    "# #         recipe_sugars = nutrition['sugars']\n",
    "# #         recipe_fiber = nutrition['fibre']\n",
    "# #         recipe_protein = nutrition['protein']\n",
    "# #         recipe_salt = nutrition['salt']\n",
    "#         ingredients_list = row[4]\n",
    "#         method = row[5]\n",
    "#         time = row[6]\n",
    "#         servings = row[8]\n",
    "#         img_url = row[9]\n",
    "        \n",
    "#         print(recipe_id, type(recipe_id))\n",
    "#         print(name, type(name))\n",
    "#         print(nutrition, type(nutrition))\n",
    "#         print(method, type(method))\n",
    "#         print(time, type(time))\n",
    "#         print(servings, type(servings))\n",
    "#         print(img_url, type(img_url))\n",
    "#         break\n",
    "\n",
    "# #             recipe = Recipe(recipe_id=recipe_id,\n",
    "# #                 recipe_name=name,\n",
    "# #                 recipe_image=img_url,\n",
    "# #                 method = method,\n",
    "# #                 ingredients=ingredients_list,\n",
    "# #                 recipe_yield=servings,\n",
    "# #                 calories=calories,\n",
    "# #                 carbohydrates=recipe_carbohydrates,\n",
    "# #                 protein=recipe_protein,\n",
    "# #                 fiber=recipe_fiber,\n",
    "# #                 fat=recipe_fat,\n",
    "# #                 salt = recipe_salt,\n",
    "# #                 sugars=recipe_sugars,\n",
    "# #                 saturated_fat=recipe_saturated_fat,\n",
    "# #                 )\n",
    "# #             session.add(recipe)\n",
    "# #         session.commit()\n"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11387, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df= pd.read_csv('C:/D-drive-18921/College/AI System Design/ingredient-phrase-tagger/final_parsing/parsed_ingredients.csv', encoding='latin-1')\n",
    "df.columns = ['recipe_id', 'parsed_ingredients']\n",
    "df1 = pd.read_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db.csv', encoding='latin-1')\n",
    "df1['parsed_ingredients'] = df['parsed_ingredients']\n",
    "df1.head()\n",
    "df1.columns\n",
    "df1['nutrition'] = df1['nutrition'].apply(ast.literal_eval)\n",
    "df1.to_csv('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db_parsed.csv', index=False, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_json('C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db_parsed.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
=======
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shreya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
>>>>>>> master
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'input': '250 gram macaroni', 'display': \"<span class='qty'>250</span><span class='unit'>gram</span><span class='name'>macaroni</span>\", 'name': 'macaroni', 'unit': 'gram', 'qty': '250'}\n"
=======
      "{'bunch', 'g', 'branch', 'can', 'pound fillet', '2-inch-thick', 'chilled', 'chunk', 'piece stick', 'stick', 'half', 'dozen', 'cup stalk', 'packet', 'bunch tablespoon', 'clove teaspoon', 'tsp.', 'sprig tablespoon', 'plump clove', 'tablespoon head', 'ounce', 'cup ounce', 'strip', 'slice', 'head teaspoon', 'twist', 'sprig teaspoon', 'bag', 'tablespoon clove', 'envelope', 'teaspoon tablespoon', 'sheet', 'cupsMexican-style', 'pound bulb', 'sprig cup', 'dash', 'lb', 'slice teaspoon', 'liter', 'ear cup', 'piece', 'pinch teaspoon', 'pound slice', 'liters', 'ounce tablespoon', 'drop', 'cup teaspoon', 'pound cup', 'gallon', 'head', '1 3/4-pound', 'pound ounce', 'ounce teaspoon', 'ear', 'fillet', 'cup sprig', 'leaf', 'bowl', 'half slice', 'teaspoon', 'stalk tablespoon', 'pint ounce', 'tsp', 'bottle', 'cup tablespoon', 'fillet teaspoon', 'cup piece', 'head clove', 'tablespoon ounce', 'tablespoon', 'ounce slice', 'cup clove', 'stalk teaspoon', 'rack', 'bunch pound', 'piece fillet', 'cloves;', 'tablespoon teaspoon', 'tablespoon cup', 'teaspoon pinch', 'ounce sprig', 'bulb', 'pound piece', 'oz', 'wedge', 'scoop', 'ounce cup', 'bunch head', 'box', 'cupturkey', 'bulb tablespoon', 'knob', 'pound', 'bunch ounce', 'litres', 'cupsturkey', 'pinch', 'stalk cup', 'tablespoon sprig', 'stalk', 'quart cup', 'stick tablespoon', 'tbsp', 'sprig', 'quart sprig', 'cup', 'piece teaspoon', 'half-pint', 'pound head', 'can ounce', 'block', 'tablespoon pound', 'slab', 'splashes', 'teaspoon cup', 'quart', 'pint cup', 'bunch clove', 'handful', 'gram', 'c.', 'clove', 'loaf', 'clove tablespoon', 'slice pound', 'cup pound', 'qt', 'lb.', 'pint', 'lbs', 'seeded', 'ml', '26-ounce', 'cup strip', 'cup slice', 'package', 'teaspoon piece', 'cube', 'pound tablespoon', 'fifth'}\n"
>>>>>>> master
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import csv\n",
    "import ast\n",
    "import re\n",
    "db_path = 'C:/D-drive-18921/College/AI System Design//aidesign-proj/back-end/data/new_recipe_db_parsed.csv'\n",
    "with open(db_path, 'r', encoding='latin-1') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        recipe_id = i\n",
    "        recipe_name = row[1]\n",
    "        nutrition = ast.literal_eval(row[4])\n",
    "        kcal = nutrition['kcal']\n",
    "        fat = nutrition['fat']\n",
    "        saturated_fat = nutrition['saturates']\n",
    "        carbs = nutrition['carbs']\n",
    "        sugars = nutrition['sugars']\n",
    "        fibre = nutrition['fibre']\n",
    "        protein = nutrition['protein']\n",
    "        salt = nutrition['salt']\n",
    "        \n",
    "        method = row[6]\n",
    "        recipe_yield = row[9]\n",
    "        img_url = row[10]\n",
    "        \n",
    "        recipe_entry = Recipe(recipe_id = recipe_id,\n",
    "                             recipe_name = recipe_name,\n",
    "                             kcal = kcal,\n",
    "                             fat = fat,\n",
    "                             saturated_fat = saturated_fat,\n",
    "                             carbs = carbs,\n",
    "                             sugars = sugars,\n",
    "                             fibre = fibre,\n",
    "                             protein = protein,\n",
    "                             salt = salt,\n",
    "                             method = '-'.join(method),\n",
    "                             recipe_yield = recipe_yield,\n",
    "                             recipe_img = img_url)\n",
    "\n",
    "        session.add(recipe_entry)\n",
    "        \n",
    "        parsed_ingr = ast.literal_eval(row[11])\n",
    "\n",
    "        for ingredient in parsed_ingr:\n",
    "            if 'name' not in ingredient:\n",
    "                continue\n",
    "            ingredient_query = session.query(Ingredient).filter_by(name=ingredient['name'])\n",
    "            if ingredient_query.count() > 0:\n",
    "                ingredient_entry = ingredient_query.first()\n",
    "            else:\n",
    "                ingredient_entry = Ingredient(name=ingredient['name'])\n",
    "                session.add(ingredient_entry)\n",
    "\n",
    "            recipe_ingredient_query = session.query(RecipeIngredient).filter_by(recipe_id=recipe_entry.recipe_id, \n",
    "                                                                                ingredient_id=ingredient_entry.ingr_id)\n",
    "            if recipe_ingredient_query.count() > 0:\n",
    "                continue\n",
    "\n",
    "            recipe_ingredient_entry = RecipeIngredient(recipe=recipe_entry, ingredient=ingredient_entry)\n",
    "            if 'qty' in ingredient:\n",
    "                recipe_ingredient_entry.quantity = ingredient['qty']\n",
    "            if 'unit' in ingredient:\n",
    "                recipe_ingredient_entry.unit = ingredient['unit']\n",
    "            recipe_entry.ingredients.append(recipe_ingredient_entry)\n",
    "            ingredient_entry.recipes.append(recipe_ingredient_entry)\n",
    "            session.add(recipe_ingredient_entry)\n",
    "            session.commit()\n",
    "\n",
    "#         kcal = nutrition['kcal']\n",
    "#         fat = nutrition['fat']\n",
    "#         saturated_fat = nutrition['saturates']\n",
    "        ### index, name, author, description, nutrition, ingredients, method, time, difficulty, servings, img_url, parsed\n",
    "\n",
    "# df = pd.read_csv(db_path)\n",
    "# df.iloc[1, :]"
=======
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "units = set()\n",
    "for x in data['parsed_ingredients']:\n",
    "    for r in x:\n",
    "        if 'unit' in list(r.keys()):\n",
    "            u = r['unit']\n",
    "            q = r['quantity']\n",
    "            words = u.split()\n",
    "            units.add(\" \".join(sorted(set(words), key=words.index)))\n",
    "units= list(units)\n",
    "\n",
    "def convert_weight(given_unit, given_quantity):\n",
    "    #### convert all weights to pounds\n",
    "    if given_unit=='g':\n",
    "        return 0.00220462*given_quantity\n",
    "    if given_unit=='oz':\n",
    "        return 0.0625*given_quantity\n",
    "    if given_unit=='cup':\n",
    "        return 0.52*given_quantity\n",
    "    if given_unit=='tbsp':\n",
    "        return 0.0326*given_quantity\n",
    "    if given_unit=='tsp':\n",
    "        return 0.010866*given_quantity\n",
    "\n",
    "def convert_weight(given_unit, given_quantity):\n",
    "    #### convert all weights to pint\n",
    "    if given_unit=='oz' or given_unit=='fl oz':\n",
    "        return 0.0625*given_quantity\n",
    "    if given_unit=='l':\n",
    "        return 2.11338*given_quantity\n",
    "    if given_unit=='ml':\n",
    "        return 0.002113*given_quantity\n",
    "    if given_unit=='gal':\n",
    "        return 8*given_quantity\n",
    "    if given_unit=='qt':\n",
    "        return 2*given_quantity\n"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d1b0fd7855da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# #             continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         print(row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 55, saw 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#def load_duration(duration_path):\n",
    "# with open(duration_path, 'r', encoding='utf-8') as f:\n",
    "#     reader = csv.reader(f, delimiter=',')\n",
    "#     for i, row in enumerate(reader):\n",
    "# #         if not row:\n",
    "# #             continue\n",
    "# #         if i==0:\n",
    "# #             continue\n",
    "#         print(row)\n",
    "df = pd.read_csv(duration_path, encoding='utf-8')\n",
    "df"
=======
   "source": [
    "names = set(\n",
    ")\n",
    "for x in data['parsed_ingredients']:\n",
    "    for r in x:\n",
    "        if 'unit' in list(r.keys()):\n",
    "            u = r['unit']\n",
    "            q = r['quantity']\n",
    "            words = u.split()\n",
    "            units.add(\" \".join(sorted(set(words), key=words.index)))\n",
    "print(units)"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 <class 'int'>\n",
      "Cauliflower & macaroni cheese <class 'str'>\n",
      "{'kcal': '446', 'fat': '17g', 'saturates': '10g', 'carbs': '57g', 'sugars': '7g', 'fibre': '2g', 'protein': '19g', 'salt': '0.68g'} <class 'str'>\n",
      "['Cook the macaroni following pack instructions, adding the cauliflower for the final 4 mins.', 'Melt the butter in a pan, then stir in the flour and mustard powder and cook for 2 mins. Gradually add the milk, stirring all the time to get a smooth sauce. Add three-quarters of the cheese and some seasoning to the sauce.', 'Drain the macaroni and cauliflower and stir into the cheese sauce. Transfer to an ovenproof dish, then sprinkle over the remaining cheese and flash under a hot grill until golden and bubbling. Serve with a green salad, if you like.'] <class 'str'>\n",
      "[{'prep': {'hrs': None, 'mins': '10 mins'}, 'cook': {'hrs': None, 'mins': '20 mins'}}] <class 'str'>\n",
      " Serves 4  <class 'str'>\n",
      "//www.bbcgoodfood.com/sites/default/files/styles/recipe/public/recipe_images/recipe-image-legacy-id--775475_10.jpg?itok=OimIr2PY <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# class Recipe(Base):\n",
    "#     __tablename__ = 'recipe'\n",
    "#     recipe_id = Column(Integer, primary_key=True)\n",
    "#     recipe_name = Column(String(100))\n",
    "#     ingredients = Column(String(2000), nullable=False)\n",
    "#     method = Column(String(250), nullable=False)\n",
    "#     recipe_img = Column(String(200), nullable=True)\n",
    "\n",
    "#     recipe_yield = Column(Integer, nullable=True)\n",
    "#     calories = Column(String(10), nullable=False)\n",
    "#     carbohydrates = Column(String(10), nullable=False)\n",
    "#     protein = Column(String(10), nullable=False)\n",
    "#     fiber = Column(String(10), nullable=False)\n",
    "#     fat = Column(String(10), nullable=False)\n",
    "#     salt = Column(String(10), nullable=False)\n",
    "#     sugars = Column(String(10), nullable=False)\n",
    "#     saturated_fat = Column(String(10), nullable=False)\n",
    "\n",
    "#recipe_path = 'recipeslist.csv'\n",
    "# def load_recipes(recipes_filename):\n",
    "with open(recipe_path, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if not row:\n",
    "            continue\n",
    "        if i==0:\n",
    "            continue\n",
    "        recipe_id = i\n",
    "        name = row[0]\n",
    "        nutrition = row[3]\n",
    "#         calories = int(nutrition['kcal'])\n",
    "#         recipe_fat = nutrition['fat']\n",
    "#         recipe_saturated_fat = nutrition['saturates']\n",
    "#         recipe_carbohyrdrates = nutrition['carbs']\n",
    "#         recipe_sugars = nutrition['sugars']\n",
    "#         recipe_fiber = nutrition['fibre']\n",
    "#         recipe_protein = nutrition['protein']\n",
    "#         recipe_salt = nutrition['salt']\n",
    "        ingredients_list = row[4]\n",
    "        method = row[5]\n",
    "        time = row[6]\n",
    "        servings = row[8]\n",
    "        img_url = row[9]\n",
    "        \n",
    "        print(recipe_id, type(recipe_id))\n",
    "        print(name, type(name))\n",
    "        print(nutrition, type(nutrition))\n",
    "        print(method, type(method))\n",
    "        print(time, type(time))\n",
    "        print(servings, type(servings))\n",
    "        print(img_url, type(img_url))\n",
    "        break\n",
    "\n",
    "#             recipe = Recipe(recipe_id=recipe_id,\n",
    "#                 recipe_name=name,\n",
    "#                 recipe_image=img_url,\n",
    "#                 method = method,\n",
    "#                 ingredients=ingredients_list,\n",
    "#                 recipe_yield=servings,\n",
    "#                 calories=calories,\n",
    "#                 carbohydrates=recipe_carbohydrates,\n",
    "#                 protein=recipe_protein,\n",
    "#                 fiber=recipe_fiber,\n",
    "#                 fat=recipe_fat,\n",
    "#                 salt = recipe_salt,\n",
    "#                 sugars=recipe_sugars,\n",
    "#                 saturated_fat=recipe_saturated_fat,\n",
    "#                 )\n",
    "#             session.add(recipe)\n",
    "#         session.commit()\n"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = list(set(req['unit']))"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "def convert(num, unit, ingred):\n",
    "    the_unit = \"\"\n",
    "    weight = 0\n",
    "    volume = False\n",
    "    mass = False\n",
    "    quantity = False\n",
    "    \n",
    "    # Testing for volume\n",
    "    if \"gal\" in unit or 'gallon' in unit:\n",
    "        the_unit = \"gallon\"\n",
    "        weight = 3785.41\n",
    "        volume = True\n",
    "    elif \"quart\" in unit or \"qt\" in unit or \"q\" in unit:\n",
    "        the_unit = \"quart\"\n",
    "        weight = 946.353\n",
    "        volume = True\n",
    "    elif \"pt\" in unit or \"pint\" in unit:\n",
    "        the_unit = \"pint\"\n",
    "        weight = 473.176\n",
    "        volume = True\n",
    "    elif \"cup\" in unit or 'c' == unit:\n",
    "        the_unit = \"cup\"\n",
    "        weight = 240\n",
    "        volume = True\n",
    "    elif (\"fl\" in unit and \"oz\" in unit) or (\"fl\" in unit and \"ounce\" in unit):\n",
    "        the_unit = \"fl oz\"\n",
    "        weight = 29.5735\n",
    "        volume = True\n",
    "    elif \"tbsp\" in unit or \"table\" in unit or \"tablespoon\" in unit:\n",
    "        the_unit = \"tablespoon\"\n",
    "        weight = 14.7868\n",
    "        volume = True\n",
    "    elif \"tsp\" in unit or \"tea\" in unit:\n",
    "        the_unit = \"teaspoon\"\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "    elif \"ml\" in unit or \"milli\" in unit:\n",
    "        the_unit = \"milliliter\"\n",
    "        weight = 1\n",
    "        volume = True\n",
    "    elif \"liter\" in unit or \"l\" == unit:\n",
    "        the_unit = \"liter\"\n",
    "        weight = 1000\n",
    "        volume = True\n",
    "    elif \"pinch\" in unit or \"bit\" or \"dash\" in unit: # extraneous cases\n",
    "        # Vocab words that we'll estimate to half a teaspoon\n",
    "        the_unit = \"teaspoon\"\n",
    "        num = 0.5\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "    elif \"drop\" in unit:\n",
    "        the_unit = \"teaspoon\"\n",
    "        num = 0.2\n",
    "        weight = 4.92892\n",
    "        volume = True\n",
    "      \n",
    "    # Testing for mass\n",
    "    elif \"metric ton\" in unit or \"mt\" in unit or \"m t\" in unit:\n",
    "        the_unit = \"metric ton\"\n",
    "        weight = 1e6\n",
    "        mass = True\n",
    "    elif \"kilo\" in unit or \"kg\" in unit:\n",
    "        the_unit = \"kilogram\"\n",
    "        weight = 1000\n",
    "        mass = True\n",
    "    elif \"gram\" in unit or \"g\" == unit:\n",
    "        the_unit = \"gram\"\n",
    "        weight = 1\n",
    "        mass = True\n",
    "    elif \"milli\" in unit or \"mg\" in unit:\n",
    "        the_unit = \"milligram\"\n",
    "        weight = 0.001\n",
    "        mass = True\n",
    "    elif (\"micro\" in unit and \"wave\" not in unit) or \"μg\" in unit or \"mcg\" in unit:\n",
    "        the_unit = \"microgram\"\n",
    "        weight = 1e-6\n",
    "        mass = True\n",
    "    elif \"ton\" in unit or \"t\" == unit:\n",
    "        the_unit = \"ton\"\n",
    "        weight = 907185\n",
    "        mass = True\n",
    "    elif \"stone\" in unit or \"st\" == unit:\n",
    "        the_unit = \"stone\"\n",
    "        weight = 6350.29\n",
    "        mass = True\n",
    "    elif \"pound\" in unit or \"lb\" in unit:\n",
    "        the_unit = \"pound\"\n",
    "        weight = 453.592\n",
    "        mass = True\n",
    "    elif \"ounce\" in unit or \"ozs\" in unit or \"oz\" in unit:\n",
    "        the_unit = \"ounces\"\n",
    "        weight = 28.3495\n",
    "        mass = True\n",
    "    else: # if no match, we express the ingredient as a quantity instead of a unit of measure\n",
    "        quantity = True\n",
    "        weight = 1\n",
    "        \n",
    "    # Convert the unit\n",
    "    output = round(weight * num, 3)\n",
    "    if volume:\n",
    "        # print('Converted', the_unit, 'to milliliters')\n",
    "        mass = 0\n",
    "        volume = output\n",
    "        cols = [ingred + '_mass', ingred + '_volume']\n",
    "        measurements = [mass, volume]\n",
    "    elif mass:\n",
    "        # print('Converted', the_unit, 'to grams')\n",
    "        mass = output\n",
    "        volume = 0\n",
    "        cols = [ingred + '_mass', ingred + '_volume']\n",
    "        measurements = [mass, volume]\n",
    "    elif quantity:\n",
    "        cols = [unit]\n",
    "        measurements = [output]\n",
    "        # print('Ingredient expressed as quantity')\n",
    "    # print(output)\n",
    "    return measurements, cols, quantity\n"
   ]
>>>>>>> master
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
